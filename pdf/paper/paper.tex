\documentclass{llncs}

\usepackage{amssymb}
% \usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{wrapfig}
\usepackage{graphicx}
%\usepackage{titling}
\usepackage{float}
\usepackage{caption}
% \usepackage{subcaption}
\usepackage{listings}
%\usepackage{fullpage}
\usepackage[scientific-notation=true]{siunitx}

%Commands for including external source code files
\newcommand{\Sscript}[2]{
  \begin{itemize}
    \item[]\lstinputlisting[caption=#2,label=#1,language=Scilab,basicstyle=\ttfamily\footnotesize,breaklines=true]{#1}
  \end{itemize}
}
\newcommand{\Rscript}[2]{
  \begin{itemize}
    \item[]\lstinputlisting[caption=#2,label=#1,language=R,basicstyle=\ttfamily\footnotesize,breaklines=true]{#1}
  \end{itemize}
}
\newcommand{\Jscript}[2]{
  \begin{itemize}
    \item[]\lstinputlisting[caption=#2,label=#1,language=Java,basicstyle=\ttfamily\footnotesize,breaklines=true]{#1}
  \end{itemize}
}

\newcommand{\Cscript}[2]{
  \begin{itemize}
    \item[]\lstinputlisting[caption=#2,label=#1,language=C,basicstyle=\ttfamily\footnotesize,breaklines=true]{#1}
  \end{itemize}
}

\newcommand{\Pscript}[2]{
  \begin{itemize}
    \item[]\lstinputlisting[caption=#2,label=#1,language=Python,basicstyle=\ttfamily\footnotesize,breaklines=true]{#1}
  \end{itemize}
}

\lstdefinelanguage{codeoutput} { %this is the name that you are going to use when you want to use the formatting
  basicstyle=\ttfamily\scriptsize, %font family & size
}
\newcommand{\Oscript}[2]{
  \begin{itemize}
    \item[]\lstinputlisting[caption=#2,label=#1,language=codeoutput]{src/#1}
  \end{itemize}
}

\setlength{\abovecaptionskip}{1pt plus 1pt minus 1pt} % Chosen fairly arbitrarily






\begin{document}
\mainmatter


\title{Does runtime prediction matter?}

\author{Eric Gaussier\inst{1} \and David Glesser\inst{2}
Denis Trystram\inst{3} \and Valentin Reis\inst{4}}

\institute{Universisty of TODO\\
\email{TODO@TODO.com},
\and
Universisty of TODO\\
\email{TODO@TODO.com},
\and
Universisty of TODO\\
\email{TODO@TODO.com},
\and
Universisty of TODO\\
\email{TODO@TODO.com}}

\maketitle              % typeset the title of the contribution

\begin{abstract}

Abstract is here.
\keywords{computational geometry, graph theory, Hamilton cycles}

\end{abstract}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{sec:introduction}
constat: l'estimation -user des runtimes est mauvaise. (est plutôt une deadline)

Les batch schedulers sont des politiques rudimentaires, simples et robustes (FIFO backfilling), qui guarantissent l'absence de famine. Ces politiques permettent une forte utilisation de la machine.
Les politiques prop. (eg torque pbs ) sont légèrement plus sophistiquées mais restent basées sur des listes.\

question: peut-on tirer parti d'une meilleure conaissance des temps de prédiction afin de mieux gérer les ressources?

On montre ici qu'en se basant sur des techniques classiques de prédiction, il es possible d'améliorer  l'allocation obtenue avec les politiques classiques (ici backfilling.).
Détail de la contribution:
-comment prédire
-nouvelles politiques pour utiliser ces prédictions
-validation expérimentale





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem Statement}
\label{sec:problem_statement}

Scheduling classic.
a machine composed of multiple nodes.
a job is made of submit time, runtime, number of required nodes.
Objective are discussed in \ref{sub:objective_functions}.In HPC, runtime is not known.
User are asked for a ``runtime'', but in fact its a maximum runtime (job is killed).
So user over-estimates this time.
Also, in some system, there is a default value.

Most theorical sched algo needs the runtime => these algo can't be used in production systems.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Learning}
\label{sec:learning}

Job runtime prediction has been first attempted~\cite{gibbons} by categorizing jobs according to a predefined set of rules and using a statistic of these categories as a prediction. In this method, often-times called "Templates" by subsequent authors, the partitioning has to be provided by the RMS or the system administrator. This model can be seen as an ancestor of tree-based regression models in which the binning has to be obtained trough statistical analysis of the specific system and population and/or discussion with a domain expert. The technique was subsequently adapted~\cite{gibbons-GA} using a more automatic way to generate the rules.

A recent survey~\cite{ML-predictruntime-survey} compares methods based on generic supervised learning tools.

All these approaches assume jobs and their run-times to be identically distributed and independent. As such, they do not make use of dependencies between job submissions.

A stochastic model~\cite{hmm} has been proposed for predicting job runtime distributions. By opposition to previous works which only used job descriptions, this technique only relies on historical run-time information. It treats successive run-times of a given user as the observations of a Hidden Markov Model~\cite{rabiner}, and hence does not make the hypothesis that job submissions are independently and identically distributed.
A related, but much simpler approach~\cite{tsafir} averages the two last available run-times of the job's user as a prediction. It enjoys surprising success given its simplicity.

Our approach is that of combining both job descriptions and temporal dependency of run-times through online linear regression.
On the other hand, we do not use system load information such as CPU or memory usage.
This choice is motivated by the prospect of using a prediction technique which necessitates as little system information as possible : Current HPC RMS rarely monitor or record this information, and it is not present in HPC logs.
In the same manner, we refrain from using application-centric modeling or any information about the jobs other than that found in the $swf$ format of the Workload Archive~\cite{workloadarchive}.

We describe here our model.

TODO:

A job is maped to a vector $x \in \mathbb{R}^{n}$ where $n$ is the number of features of our model.
The prediction is achieved via a Generalized Linear Model:
\[
  y = w^{\intercal} \Phi(x)
\]
Where $\phi(x)$ is ...




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Scheduling strategies}
\label{sec:scheduling_strategies}


\subsection{Objective Functions}
\label{sub:objective_functions}

Cmax : not applicable in our case.

Flow : good, but...

Stretch : good, but...

Max, L1, L2, L2... ?

\section{Scheduling algorithms}
\label{sec:scheduling_algorithms}

FIFO

FIFO+EASY backfill

In real system :
Slurm: Ordered list + Best fit backfill
OAR: ??
PBS: ???
...




\subsection{Backfilling with Correction}
\label{sub:backfilling_with_correction}

guessing runtime =>
over-estimation : same problem without, which are...
under-estimation : new problem ! EASY backfill garantee that a job N will not be delayed by a job N+x.
If an N+x job is backfilled before N, N can be delayed due to this job. There is even a situation when a job can starve.

Which strategies to counter this ?
reqtime: if over estimation => user reqtime
tsafrir: +1min, then +5min, then 15min, then 1h...
ninetynine: ``if runtime>prediction, then "99\% of jobs are shorter than" value,''
recursive doubling: we double the already run time




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experimental Validation}
\label{sec:experimental_validation}

\subsection{Testbed}
\label{sub:Testbed}
Use Pyss, core improved to a newer python version and add algo. Code sourve available there XX.
Tests the following algo:
-
-

Tests with the following workload (from the FWA):
- CEA-curie
- CTC-SP2
- KTH-SP2
- SDSC-BLUE
- SDSC-SP2
- More? (see used traces for FSE)


\subsection{Results}
\label{sub:Testbed}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion}
\label{sec:conclusion}





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements.}
\label{sec:ack}
merci yannis ect

-cite
workload archive
pyss


\bibliographystyle{splncs03}
\bibliography{bibliography}


\end{document}
