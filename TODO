**** estimation ****
- ajouter un historique pour stocker les données
- utiliser l'API:class Predictor
- migrer les predictors vers cette API
-feature scaled stochastic gradient descent (with regularization???)

(- nouvelle fonction de cout)


**** simulateur ****
- vérifier toutes les algos : certaines sont justes des instances d'autres.

-ajouter un check pour verifier que "fit" et "predict" est appelé une fois par job seulement (respct al a soumission et la fin du job)

-algos:
prévoir toutes les combinaisons:
priority list: FCFS
backfill: EASY, EASY+SJBF
correction:
	reqtime (assume reqtime if runtime >prediction),
	tsafrir(if runtime > prediction, then +1mn, +2mn,+5mn,+10mn.. cf papier),
	if runtime>prediction, then "99% of jobs are shorter than" value,
	"wait"(stop backfilling (and scheduling) as soon as "shadow" reservation is delayed)
	(Denis risky : prendre un facteur de risque global. Il croit lorsqu'on se trompe, il diminue lorsqu'on est bon. Plus le facteur de risque est élevé, plus on corrige de façon ample (pour esperer diminuer le facteur de risque).)
	recursive doubling: a chaque erreur on double le temps 

(- faire des tests unitaires)
(- possibilité de changer l'algo de selection, avoir du continu, hierarchique...)

**** workload ****
*recuperer les logs et formater(filtrer) pour expés:
-logs feitelson
-4 logs papier easy++
*preparation des donnees:
filtrer runtime 0 -> runtime 1

**For reference:
API:
see predictor/predictor.py :)
GIT stuff:
git submodule init
git submodule update


**** measures ****
(ie. que faut-il mesurer dans les traces simulés ?)
=> combien de jobs sont corrigés ?
=> stretch....

